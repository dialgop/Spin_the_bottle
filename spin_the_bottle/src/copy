#include <opencv2/highgui/highgui.hpp>

#include <ros/ros.h>
#include <image_transport/image_transport.h>
#include <cv_bridge/cv_bridge.h>

#include <actionlib/client/simple_action_client.h>
#include <actionlib/client/terminal_state.h>
#include <naoqi_msgs/JointTrajectoryGoal.h>
#include <naoqi_msgs/JointTrajectoryAction.h>

#include "../include/bottle_recognition/LineProjectionE.h"
#include "../include/bottle_recognition/WorldCoordinates.h"
#include "../include/bottle_recognition/PreGame.h"
#include "ActionNaoNeck.cpp"

#include <iostream>
#include <math.h>

using namespace std;
using namespace cv;

Point3d timeBefore, timeAfter;
int counter=0;
vector <double> pitchAndYaw;
Point2d coordinates;
Mat imageBefore, imageAfter;
bool bottleDetected = false , movementDetected = true;
int counterTimesHead = 0;
bool isAbleToMoveHead = false;
int cameraUsed = 1;
ActionNaoNeck ac;

/*naoqi_msgs::JointTrajectoryGoal putHeadDown()
{
    naoqi_msgs::JointTrajectoryGoal goal;
    goal.relative = false;
    goal.trajectory.joint_names.push_back("HeadPitch");
    goal.trajectory.joint_names.push_back("HeadYaw");

    goal.trajectory.points.resize(2);
    int step = 0;

    goal.trajectory.points[step].positions.resize(2);
    goal.trajectory.points[step].positions[0] = 0.075124;
    goal.trajectory.points[step].positions[1] = 0.0137641;
    goal.trajectory.points[step].velocities.resize(2);
    for (size_t j = 0; j < goal.trajectory.joint_names.size(); ++j)
    {
        goal.trajectory.points[step].velocities[j] = 0.0;
    }

    goal.trajectory.points[step].time_from_start = ros::Duration(1);
    ++step;

    goal.trajectory.points[step].positions.resize(2);
    goal.trajectory.points[step].positions[0] = 0.075124;
    goal.trajectory.points[step].positions[1] = 0.0137641;
    goal.trajectory.points[step].velocities.resize(2);
    for (size_t j = 0; j < goal.trajectory.joint_names.size(); ++j)
    {
        goal.trajectory.points[step].velocities[j] = 0.0;
    }

    goal.trajectory.points[step].time_from_start = ros::Duration(1.84);

    return goal;
}

naoqi_msgs::JointTrajectoryGoal MoveToAngle()
{
//	cout << "pitch in MoveToAngle" << pitchAndYaw[0] << endl;
//	cout << "yaw in MoveToAngle" << pitchAndYaw[1] << endl;

    naoqi_msgs::JointTrajectoryGoal goal;
    goal.relative = false;
    goal.trajectory.joint_names.push_back("HeadPitch");
    goal.trajectory.joint_names.push_back("HeadYaw");

    goal.trajectory.points.resize(2);
    int step = 0;
    goal.trajectory.points[step].positions.resize(2);
    goal.trajectory.points[step].positions[0] = pitchAndYaw.at(0)-(PI/4);
    goal.trajectory.points[step].positions[1] = pitchAndYaw.at(1)-(PI/2);

    goal.trajectory.points[step].velocities.resize(2);
    for (size_t j = 0; j < goal.trajectory.joint_names.size(); ++j)
    {
        goal.trajectory.points[step].velocities[j] = 0.0;
    }

    goal.trajectory.points[step].time_from_start = ros::Duration(1 + 0.5);
    ++step;

    goal.trajectory.points[step].positions.resize(2);
    goal.trajectory.points[step].positions[0] = pitchAndYaw.at(0)-(PI/4);
    goal.trajectory.points[step].positions[1] = pitchAndYaw.at(1)-(PI/2);
    goal.trajectory.points[step].velocities.resize(2);
    for (size_t j = 0; j < goal.trajectory.joint_names.size(); ++j)
    {
        goal.trajectory.points[step].velocities[j] = 0.0;
    }

    goal.trajectory.points[step].time_from_start = ros::Duration(2.50 + 0.5);

    return goal;
}*/

void performHandMotion()
{
	 naoqi_msgs::JointTrajectoryGoal goal= ac_handmotion::getHandMotion();
	 isfunctionCallok = AC_HANDMOTION->perform(goal);
	 if (isfunctionCallok != 0)	{
		 ROS_ERROR("Unable to perform hand motion");
	 }
}

void imageCallback(const sensor_msgs::ImageConstPtr& msg)
{
	if(cameraUsed == 1)
	{
		isAbleToMoveHead = false;
		bool firstImage = true, between0and180 = false;

		cv::Mat imageWithoutModifications = cv_bridge::toCvShare(msg, "bgr8")->image;

		try
		{
			cv::Mat sourceImage = cv_bridge::toCvShare(msg, "bgr8")->image;

			PreGame beforeGame(sourceImage);

			bottleDetected = beforeGame.BottleDetected(sourceImage);

			if(bottleDetected == true)
			{
				imageAfter = sourceImage;

				if(firstImage == true)
				{
					imageBefore = sourceImage;
					firstImage = false;
				}

				movementDetected = beforeGame.MovementDetected(imageBefore, imageAfter);

				imageBefore = imageAfter;

				if(movementDetected == false)
				{
					vector<Point3d> xyangles;
					vector<int> orienting;

			//Create a class called line projection and another one called WorldCoordinates

					LineProjectionE lineProjection(sourceImage);

			/* On the class called line projection, detects
			 * the orientation where the bottle points*/

					orienting = lineProjection.FindPointingArea(sourceImage);

			/* Having obtained the value from the variable called
			 * orienting, makes the projection using a fitEllipse */

					xyangles = lineProjection.drawPointingLine(sourceImage, orienting);

					//First frame is gotten by xyangle
					//timeBefore in first time is = 0;

					counter++;

					//Wait until 10 to make a change on the values;

					timeAfter = xyangles.at(0);

					bool moveDetection;
					//Comparison of angles

					if((timeBefore.x + 5 > timeAfter.x && timeAfter.x > timeBefore.x - 5)
							&& ((timeBefore.y + 5 > timeAfter.y && timeAfter.y > timeBefore.y - 5))
							&& ((timeBefore.z + 2 > timeAfter.z && timeAfter.z > timeBefore.z - 2)))
					{
						moveDetection = false;
					}
					else
					{
						moveDetection = true;
					}

					if(counter == 10)
					{
						timeBefore = timeAfter;
						counter = 0;
					}

			//Creates a class called World coordinates if there is no movement detection

					if(moveDetection == false)
					{
						vector<double> centerAndEdgeInWorld;

						WorldCoordinates naoWorldCoordinates(xyangles, sourceImage);

						centerAndEdgeInWorld = naoWorldCoordinates.getWorldCoordinates(xyangles, sourceImage);
						/*cout << "center in world.x: " << centerAndEdgeInWorld.at(0) << " cm from nao" << endl;
						cout << "center in world.y: " << centerAndEdgeInWorld.at(1) << " cm from nao" <<endl;
						cout << "center.z: " << centerAndEdgeInWorld.at(2) << " cm from nao" <<endl;
						cout << "edge.x: " << centerAndEdgeInWorld.at(3) << " cm from nao" <<endl;
						cout << "edge.y: " << centerAndEdgeInWorld.at(4) << " cm from nao" <<endl;
						cout << "edge.z: " << centerAndEdgeInWorld.at(5) << " cm from nao" <<endl;
						cout << "angle: " << centerAndEdgeInWorld.at(6) << endl;*/
						coordinates = naoWorldCoordinates.getPointingCoordinates(centerAndEdgeInWorld);

						cout << "coordinates" << coordinates << endl;

						if(coordinates.x != -1 && coordinates.y != -1)
						{
							isAbleToMoveHead = true;
							pitchAndYaw = naoWorldCoordinates.getPitchYawHead(centerAndEdgeInWorld,coordinates);
	//						cout << "pitch" << pitchAndYaw.at(0) << " Yaw: " << pitchAndYaw.at(1) <<endl;
						}
						else
						{
							isAbleToMoveHead = false;
						}
					}
					cv::imshow("view",sourceImage);
				}
				cv:waitKey(10);

				//ROS_INFO("We are here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");

				/*cout << "bottleDetected: " << bottleDetected << endl;
				cout << "movementDetected: " << movementDetected << endl;
				cout << "pitchAndYaw.size()" << pitchAndYaw.size() << endl;
				cout << "counterTimesHead<1" << counterTimesHead << endl;
				cout << "isAbleToMoveHead" << isAbleToMoveHead << endl;*/

				if(bottleDetected == true && movementDetected == false && pitchAndYaw.size()==2 && counterTimesHead < 1 && isAbleToMoveHead == true)
				{
					counterTimesHead++;
					ActionNaoNeck ac = new ActionNaoNeck();
					ac.

					ROS_INFO("inside action lib move head angle here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
					actionlib::SimpleActionClient<naoqi_msgs::JointTrajectoryAction>ac("/joint_trajectory", true);
					ROS_INFO("Waiting for action server to start");
					ac.waitForServer();
					ac.sendGoal(MoveToAngle());
					bool finishedBeforeTimeout = ac.waitForResult(ros::Duration(15.0));
					if(finishedBeforeTimeout)
					{
							actionlib::SimpleClientGoalState state = ac.getState();
							ROS_INFO("Action finished: %s", state.toString().c_str());
					}
					else
					{
						ROS_INFO("Action did not finish before the time out.");
					}
					system("rosrun dynamic_reconfigure dynparam set naoqicamera_node source 0");
					cameraUsed = 0;
				}
			}
			else
			{
				cv::imshow("view",cv_bridge::toCvShare(msg, "bgr8")->image);
			}
		}
		catch (cv_bridge::Exception& e)
		{
			ROS_ERROR("Could not convert from '%s' to 'bgr8'.", msg -> encoding.c_str());
		}
	}
	else
	{
		cv::imshow("view",cv_bridge::toCvShare(msg, "bgr8")->image);
	}

}

int main(int argc, char **argv)
{
	system("rosrun dynamic_reconfigure dynparam set naoqicamera_node source 1");
	cameraUsed = 1;
	ros::init(argc, argv, "image_listener");
	ros::NodeHandle nh;
	ros::Rate loop_rate(20);
	actionlib::SimpleActionClient<naoqi_msgs::JointTrajectoryAction>ac("/joint_trajectory", true);
	ROS_INFO("Waiting for action server to start.");
	ac.waitForServer();
	ac.sendGoal(putHeadDown());
	//ROS_INFO("blablabalbalabal");
	bool finishedBeforeTimeout = ac.waitForResult(ros::Duration(15.0));
	if(finishedBeforeTimeout)
	{
        	actionlib::SimpleClientGoalState state = ac.getState();
        	ROS_INFO("Action finished: %s", state.toString().c_str());
	}
	else
	{
		ROS_INFO("Action did not finish before the time out.");
	}
  	cv::namedWindow("view");
  	cv::startWindowThread();

  	image_transport::ImageTransport it(nh);
  	image_transport::Subscriber sub = it.subscribe("camera/image_raw", 1, imageCallback);

  	ros::spin();
  	cv::destroyWindow("view");
}